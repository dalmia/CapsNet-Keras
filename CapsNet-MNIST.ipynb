{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capsule Networks\n",
    "\n",
    "This is a Keras implementation of the CapsNet architecture proposed in https://arxiv.org/abs/1710.09829, to be submitted to the [Global NIPS implementation Challenge](https://nurture.ai/nips-challenge)."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
=======
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Input, Model\n",
<<<<<<< HEAD
    "from keras.layers import Conv2D, Dense, Flatten, Reshape, Dot, Multiply\n",
=======
    "from keras.layers import Conv2D, Dense, Flatten, Reshape, Dot\n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.activations import softmax\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
<<<<<<< HEAD
    "from os.path import exists, join\n",
    "from os import mkdir\n",
    "\n",
    "import shutil\n",
=======
    "from os.path import exists\n",
    "from os import mkdir\n",
    "\n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 54,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10                       # Number of different classes (10 here for 0-9)\n",
    "IMG_WIDTH = 28                         # Width of each image\n",
    "IMG_HEIGHT = 28                        # Height of each image\n",
    "NUM_CHANNELS = 1                       # Number of channels in each image (1 here, for grayscale)\n",
    "BATCH_SIZE = 128                       # Batch size to be used while training\n",
    "EPOCHS = 500                           # Number of epochs to train the model for\n",
    "RECONSTRUCTION_REG = 0.0005            # Regularization factor multiplied with the reconstruction loss\n",
    "LEARNING_RATE = 1e-4                   # Initial Learning rate used while training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 136,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squash(Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Squash, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(Squash, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x_norm = K.expand_dims(Norm()(x))\n",
    "        return (K.square(x_norm) / (1 + K.square(x_norm))) * x / (x_norm + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 137,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(Layer):\n",
    "    \n",
    "    def __init__(self, num_sharing_capsules=32, num_channels_per_capsule=8, kernel_size=9, **kwargs):\n",
    "        self.num_sharing_capsules = num_sharing_capsules\n",
    "        self.num_channels_per_capsule = num_channels_per_capsule\n",
    "        self.kernel_size = kernel_size\n",
    "        super(PrimaryCaps, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(PrimaryCaps, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        primary_caps_conv_out = Conv2D(filters=self.num_sharing_capsules * self.num_channels_per_capsule,\n",
    "                                       kernel_size=self.kernel_size,\n",
    "                                       strides=(2, 2))(x)\n",
    "        primary_caps_out = Reshape((-1, self.num_channels_per_capsule))(primary_caps_conv_out)                                       \n",
    "        return Squash()(primary_caps_out)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        img_size = input_shape[1]\n",
<<<<<<< HEAD
    "        out_size = (img_size - self.kernel_size + 1) / 2\n",
=======
    "        out_size = img_size - self.kernel_size + 1\n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "        return (input_shape[0], out_size * out_size * self.num_sharing_capsules, \n",
    "                self.num_channels_per_capsule)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_sharing_capsules': self.num_sharing_capsules,\n",
    "            'num_channels_per_capsule': self.num_channels_per_capsule,\n",
    "            'kernel_size': self.kernel_size\n",
    "        }\n",
    "        base_config = super(PrimaryCaps, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 254,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(Layer):\n",
    "    \n",
<<<<<<< HEAD
    "    \n",
=======
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "    def __init__(self, routing_iter=3, num_capsules=NUM_CLASSES, \n",
    "                 num_channels_per_capsule=16,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.routing_iter = routing_iter\n",
    "        self.num_capsules = num_capsules\n",
    "        self.num_channels_per_capsule = num_channels_per_capsule\n",
    "        \n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        \n",
    "        super(DigitCaps, self).__init__(**kwargs)\n",
    "    \n",
<<<<<<< HEAD
    "    \n",
=======
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(self.num_capsules, input_shape[1],\n",
    "                                        input_shape[2], \n",
    "                                        self.num_channels_per_capsule), \n",
    "                                 name='W',\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 regularizer=self.kernel_regularizer,\n",
    "                                 constraint=self.kernel_constraint)\n",
    "        \n",
    "        super(DigitCaps, self).build(input_shape)\n",
<<<<<<< HEAD
    "         \n",
    "        \n",
    "    def call(self, x):\n",
    "        x_shape = x.get_shape().as_list()\n",
    "        b = K.zeros((self.num_capsules, x_shape[1]))\n",
    "        b = Input(tensor=b)\n",
    "        x = K.repeat_elements(K.expand_dims(x, axis=1), self.num_capsules, axis=1)\n",
    "        \n",
    "        x_hat = K.map_fn(lambda i: K.batch_dot(i, self.W, axes=0), elems=x)\n",
    "        \n",
    "        for i in range(self.routing_iter):\n",
    "            c = softmax(b, axis=-1)\n",
    "            s = K.map_fn(lambda x: Dot(axes=1)([x, c]), elems=x_hat)\n",
    "            v = Squash()(s)\n",
    "            \n",
    "            v_expanded = K.repeat_elements(K.expand_dims(v, 2), x_shape[1], axis=2)\n",
    "            update = Multiply()([v_expanded, x_hat])\n",
    "            update = K.sum(update, axis=-1)\n",
    "            update = K.sum(update, axis=0)\n",
    "            b += update\n",
    "            \n",
    "        return v\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.num_capsules, self.num_channels_per_capsule)\n",
    "    \n",
    "    \n",
=======
    "        \n",
    "    def call(self, x):\n",
    "        b = K.zeros((self.num_capsules, x.get_shape().as_list()[1]))\n",
    "        b = Input(tensor=b)\n",
    "        x_hat = Dot(axes=2)([x, self.W])\n",
    "        \n",
    "        for i in range(self.routing_iter):\n",
    "            c = softmax(b, axis=-1)\n",
    "            print(c.shape)\n",
    "            s = Dot(axes=1)([c, x_hat])            \n",
    "            v = Squash()(s)\n",
    "            v_shape = v.get_shape().as_list()\n",
    "            v_reshape = K.reshape(v, (v_shape[0], 1, v_shape[1]))\n",
    "            print(x_hat.shape)\n",
    "            update = Dot(axes=2)([v_reshape, x_hat])\n",
    "            b += update\n",
    "        \n",
    "        return v\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.num_capsules, self.num_channels_per_capsule)\n",
    "    \n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "    def get_config(self):\n",
    "        config = {\n",
    "            'routing_iter': self.routing_iter,\n",
    "            'num_capsules': self.num_capsules,\n",
    "            'num_channels_per_capsule': self.num_channels_per_capsule,\n",
    "        }\n",
    "        base_config = super(DigitCaps, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 20 and 10 for 'digit_caps_36/dot_87/MatMul' (op: 'BatchMatMul') with input shapes: [20,1152,8,1], [10,1152,8,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-0b1067ae2529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1152\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Dot(axes=1)([a, b])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mDigitCaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-254-9b803f93315a>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_capsules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouting_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/keras/layers/merge.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mbatch_dot\u001b[0;34m(x, y, axes)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0madj_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madj_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx_ndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1784\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m       return gen_math_ops._batch_mat_mul(\n\u001b[0;32m-> 1786\u001b[0;31m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36m_batch_mat_mul\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m    288\u001b[0m   \"\"\"\n\u001b[1;32m    289\u001b[0m   result = _op_def_lib.apply_op(\"BatchMatMul\", x=x, y=y, adj_x=adj_x,\n\u001b[0;32m--> 290\u001b[0;31m                                 adj_y=adj_y, name=name)\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 20 and 10 for 'digit_caps_36/dot_87/MatMul' (op: 'BatchMatMul') with input shapes: [20,1152,8,1], [10,1152,8,16]."
     ]
    }
   ],
   "source": [
    "b = K.zeros((10, 1152, 8, 16))\n",
    "a = K.zeros((20, 1152, 8))\n",
    "# Dot(axes=1)([a, b])\n",
    "DigitCaps()(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mask, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(Mask, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
<<<<<<< HEAD
    "        if isinstance(x, list):\n",
    "            x, mask = x\n",
    "            \n",
    "        else:\n",
    "            norm = Norm()(x)\n",
    "            \n",
    "            mask = K.argmax(norm)\n",
    "            mask = K.one_hot(mask, num_classes=x.get_shape().as_list()[1])\n",
    "            \n",
    "        masked_digit_cap = K.batch_flatten(x * K.expand_dims(mask))            \n",
    "        return masked_digit_cap\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            return (input_shape[0][0], input_shape[0][1] * input_shape[0][-1])\n",
    "        \n",
    "        return (input_shape[0], input_shape[1] * input_shape[-1])"
=======
    "        digit_caps_out, y = x\n",
    "        digit_caps_out_shape = K.int_shape(digit_caps_out)\n",
    "        true_digit_idx = K.argmax(y)\n",
    "        true_digit_idx = K.cast(true_digit_idx, dtype='int32')\n",
    "        true_digit_idx_flat = tf.range(0, digit_caps_out_shape[0]) * digit_caps_out_shape[1]  + true_digit_idx\n",
    "        masked_digit_cap = K.gather(K.reshape(digit_caps_out, (-1, digit_caps_out_shape[-1])), \n",
    "                                    true_digit_idx_flat)\n",
    "        return masked_digit_cap"
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": 60,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "    \n",
<<<<<<< HEAD
    "    def __init__(self, shape, **kwargs):\n",
    "        self.shape = shape\n",
=======
    "    def __init__(self, **kwargs):\n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "        super(Decoder, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(Decoder, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
<<<<<<< HEAD
    "        dense1_out = Dense(512, activation='relu', name='decoder_dense1')(x)\n",
    "        dense2_out = Dense(1024, activation='relu', name='decoder_dense2')(dense1_out)\n",
    "        dense3_out = Dense(784, activation='sigmoid', name='decoder_final')(dense2_out)\n",
    "        dense3_out = Reshape(self.shape)(dense3_out)\n",
    "        \n",
    "        return dense3_out\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.shape[0], self.shape[1], self.shape[2])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'shape': self.shape,\n",
    "        }\n",
    "        base_config = super(Decoder, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
=======
    "        dense1_out = Dense(512, activation='relu', name='decoder_dense1')\n",
    "        dense2_out = Dense(1024, activation='decoder_dense2')\n",
    "        dense3_out = Dense(784, activation='sigmoid')\n",
    "        return dense3_out\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 784)"
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": 104,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Norm, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(Norm, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return K.sqrt(K.sum(K.square(x), axis=-1))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 66,
=======
   "execution_count": 90,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(object):\n",
    "    \n",
<<<<<<< HEAD
    "    def __init__(self, x_train, y_train, x_test, y_test, routing_iter=3, \n",
=======
    "    def __init__(self, x_train, y_train, x_test, y_test, routing_iter=1, \n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "                 learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                 rec_reg=RECONSTRUCTION_REG, log_dir='./tb_logs/', checkpoint_dir='./weights'):\n",
    "        \n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.routing_iter = routing_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.rec_reg = rec_reg\n",
    "        self.log_dir = log_dir\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        \n",
<<<<<<< HEAD
    "        if exists(log_dir):\n",
    "            shutil.rmtree(log_dir)\n",
    "            shutil.rmtree(checkpoint_dir)\n",
    "        \n",
    "        mkdir(log_dir)\n",
    "        mkdir(checkpoint_dir)\n",
    "            \n",
    "    def custom_margin_loss(self, y_true, y_pred):\n",
    "        m_plus = 0.9\n",
    "        m_minus = 0.1\n",
    "        down_weigh = 0.5\n",
    "        loss = y_true * K.square(K.maximum(0., m_plus - y_pred)) + \\\n",
    "               down_weigh * (1 - y_true) * K.square(K.maximum(0., y_pred - m_minus))\n",
    "        return K.mean(K.sum(loss, axis=-1))\n",
    "        \n",
    "    def build_model(self):\n",
    "        input_shape = (IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)\n",
    "        x = Input(shape=input_shape)\n",
    "        y = Input(shape=(NUM_CLASSES,))\n",
    "        \n",
    "        conv_out = Conv2D(filters=256, kernel_size=9, activation='relu', name='conv')(x)\n",
    "        primary_caps_out = PrimaryCaps(name='primary_caps')(conv_out)\n",
    "        digit_caps_out = DigitCaps(name='digit_caps')(primary_caps_out)\n",
    "        \n",
    "        masked_digit_cap = Mask(name='mask_true')([digit_caps_out, y])\n",
    "        masked_pred_digit_cap = Mask(name='mask_pred')(digit_caps_out)\n",
    "        \n",
    "        reconstructed_out = Decoder(shape=input_shape)(masked_digit_cap)\n",
    "        pred_reconstructed_out = Decoder(shape=input_shape)(masked_pred_digit_cap)\n",
    "        pred_prob = Norm(name='pred_prob')(digit_caps_out)\n",
    "        \n",
    "        train_model = Model(inputs=[x, y], outputs=[pred_prob, reconstructed_out])\n",
    "        pred_model = Model(inputs=[x, y], outputs=[pred_prob, pred_reconstructed_out])\n",
    "        \n",
    "        train_model.compile(optimizer=Adam(lr=self.learning_rate), \n",
=======
    "        if not exists(log_dir):\n",
    "            mkdir(log_dir)\n",
    "            mkdir(checkpoint_dir)\n",
    "            \n",
    "    def custom_margin_loss(y_true, y_pred):\n",
    "        m_plus = 0.9\n",
    "        m_minus = 0.1\n",
    "        down_weigh = 0.5\n",
    "        loss = y_true * K.square(K.maximum(0., m_plus - y_pred)) + down_weigh * (1 - y_true) * K.square(K.maximum(0., y_pred - m_minus))\n",
    "        return K.mean(K.sum(loss, axis=-1))\n",
    "        \n",
    "    def build_model(self):\n",
    "        x = Input(shape=(IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS))\n",
    "        y = Input(shape=(NUM_CLASSES))\n",
    "        \n",
    "        conv_out = Conv2D(filters=256, kernel_size=9, activation='relu', name='conv')(x)\n",
    "        primary_caps_out = PrimaryCaps(name='primary_caps')(out)\n",
    "        digit_caps_out = DigitCaps(name='digit_caps')(out)\n",
    "        \n",
    "        masked_digit_cap = Mask(mame='mask')([digit_caps_out, y])\n",
    "        \n",
    "        reconstructed_out = Decoder()(masked_digit_cap)\n",
    "        pred_prob = Norm(name='pred_prob')(digit_caps_out)\n",
    "        \n",
    "        model = Model(inputs=[x, y], outputs=[pred_prob, reconstructed_out])\n",
    "        model.compile(optimizer=Adam(lr=self.learning_rate), \n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "                      loss=[self.custom_margin_loss, 'mse'], \n",
    "                      loss_weights=[1, self.rec_reg],\n",
    "                      metrics={'pred_prob': 'accuracy'})\n",
    "        \n",
<<<<<<< HEAD
    "        pred_model.compile(optimizer=Adam(lr=self.learning_rate), \n",
    "                           loss=[self.custom_margin_loss, 'mse'],\n",
    "                           loss_weights=[1, self.rec_reg],\n",
    "                           metrics={'pred_prob': 'accuracy'})\n",
    "        \n",
    "        return train_model, pred_model\n",
    "    \n",
    "    \n",
    "    def data_generator(self, x, y, mode='train', fraction_shifted=0.1):    \n",
=======
    "        return model\n",
    "    \n",
    "    def data_generator(x, y, mode='train', fraction_shifted=0.1):    \n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "        if(mode == 'train'):\n",
    "            data_gen = ImageDataGenerator(1/255., height_shift_range=fraction_shifted, \n",
    "                                          width_shift_range=fraction_shifted,\n",
    "                                          fill_mode='constant',\n",
    "                                          cval=0)\n",
    "        else:\n",
    "            data_gen = ImageDataGenerator(1/255.)\n",
    "            \n",
    "        data_gen = data_gen.flow(x, y, batch_size=self.batch_size)\n",
    "        while(True):\n",
    "            x, y = data_gen.next()\n",
    "            yield([x, y], [y, x])\n",
    "    \n",
<<<<<<< HEAD
    "    \n",
    "    def train(self, model):\n",
=======
    "    def train():\n",
    "        model = self.build_model()\n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "\n",
    "        tb = TensorBoard(log_dir=self.log_dir, histogram_freq=0,\n",
    "                         write_graph=True, write_images=False)\n",
    "\n",
    "        checkpointer = ModelCheckpoint(join(self.checkpoint_dir, 'chkpts.{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "                                       monitor='val_loss', save_best_only=True, \n",
    "                                       save_weights_only=False, verbose=1)\n",
    "        print('Fitting model...')\n",
    "        \n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(self.x_train, self.y_train,\n",
    "                                                              test_size=0.2, random_state=0)\n",
    "        \n",
<<<<<<< HEAD
    "        train_datagen = self.data_generator(x_train, y_train)\n",
    "        train_steps = len(x_train) // self.batch_size\n",
    "        valid_datagen = self.data_generator(x_valid, y_valid, mode='valid')\n",
    "        valid_steps = len(x_valid) // self.batch_size\n",
    "        \n",
    "        model.fit_generator(train_datagen,\n",
    "                            steps_per_epoch=train_steps, \n",
    "                            epochs=self.epochs, \n",
    "                            verbose=1,\n",
    "                            validation_data=valid_datagen,\n",
    "                            validation_steps=valid_steps,\n",
    "                            callbacks=[checkpointer, tb])\n",
=======
    "        train_datagen = data_generator(x_train, y_train)\n",
    "        train_steps = len(x_train) // self.batch_size\n",
    "        valid_datagen = data_generator(x_valid, y_valid, mode='valid')\n",
    "        valid_steps = len(x_valid) // self.batch_size\n",
    "        \n",
    "        model.fit(train_datagen,\n",
    "                  steps_per_epoch=train_steps, \n",
    "                  batch_size=self.batch_size, \n",
    "                  epochs=self.epochs, \n",
    "                  verbose=1,\n",
    "                  validation_data=valid_datagen,\n",
    "                  validation_steps=valid_steps,\n",
    "                  shuffle=True, \n",
    "                  callbacks=[checkpointer, tb])\n",
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
    "        \n",
    "        _, _, test_acc = model.evaluate([self.x_test, self.y_test], [self.y_test, self.x_test])\n",
    "        print('Test accuracy: %.4f' % test_acc)\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 67,
=======
   "execution_count": 40,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 68,
=======
   "execution_count": 41,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 68,
=======
     "execution_count": 41,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape  # Input should be a 4-D array, so we need to reshape this"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 69,
=======
   "execution_count": 42,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
<<<<<<< HEAD
     "execution_count": 69,
=======
     "execution_count": 42,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype  # The input type should be 'float' "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 70,
=======
   "execution_count": 43,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 70,
=======
     "execution_count": 43,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape  # The labels should be one-hot encoded, so we need to convert this"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 71,
=======
   "execution_count": 46,
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the 3-D input images to 4-D and converting their data types to np.float32\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1).astype(np.float32)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1).astype(np.float32)\n",
    "\n",
    "\n",
    "# Making the labels one-hot encoded\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "caps_net = CapsNet(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model, pred_model = caps_net.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv (Conv2D)                    (None, 20, 20, 256)   20992       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "primary_caps (PrimaryCaps)       (None, 1152, 8)       0           conv[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "digit_caps (DigitCaps)           (None, 10, 16)        1474560     primary_caps[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "mask_pred (Mask)                 (None, 160)           0           digit_caps[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "pred_prob (Norm)                 (None, 10)            0           digit_caps[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "decoder_2 (Decoder)              (None, 28, 28, 1)     0           mask_pred[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,495,552\n",
      "Trainable params: 1,495,552\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Epoch 1/500\n",
      "\r",
      "  1/375 [..............................] - ETA: 593s - loss: 4.5849 - pred_prob_loss: 0.8100 - decoder_1_loss: 7549.7061 - pred_prob_acc: 0.0859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/375 [..............................] - ETA: 561s - loss: 4.4965 - pred_prob_loss: 0.8100 - decoder_1_loss: 7372.9504 - pred_prob_acc: 0.0898\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/375 [..............................] - ETA: 549s - loss: 4.4724 - pred_prob_loss: 0.8100 - decoder_1_loss: 7324.8861 - pred_prob_acc: 0.1042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  4/375 [..............................] - ETA: 542s - loss: 4.5239 - pred_prob_loss: 0.8100 - decoder_1_loss: 7427.7001 - pred_prob_acc: 0.0996\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  5/375 [..............................] - ETA: 538s - loss: 4.4949 - pred_prob_loss: 0.8100 - decoder_1_loss: 7369.8640 - pred_prob_acc: 0.0938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  6/375 [..............................] - ETA: 535s - loss: 4.5033 - pred_prob_loss: 0.8100 - decoder_1_loss: 7386.6416 - pred_prob_acc: 0.0951\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  7/375 [..............................] - ETA: 532s - loss: 4.4884 - pred_prob_loss: 0.8100 - decoder_1_loss: 7356.8909 - pred_prob_acc: 0.0926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  8/375 [..............................] - ETA: 529s - loss: 4.5014 - pred_prob_loss: 0.8100 - decoder_1_loss: 7382.7273 - pred_prob_acc: 0.0947\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  9/375 [..............................] - ETA: 527s - loss: 4.4891 - pred_prob_loss: 0.8100 - decoder_1_loss: 7358.1615 - pred_prob_acc: 0.1007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 10/375 [..............................] - ETA: 525s - loss: 4.4863 - pred_prob_loss: 0.8100 - decoder_1_loss: 7352.5025 - pred_prob_acc: 0.1070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 11/375 [..............................] - ETA: 523s - loss: 4.4914 - pred_prob_loss: 0.8100 - decoder_1_loss: 7362.7710 - pred_prob_acc: 0.1122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 12/375 [..............................] - ETA: 521s - loss: 4.4829 - pred_prob_loss: 0.8100 - decoder_1_loss: 7345.7293 - pred_prob_acc: 0.1191\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 13/375 [>.............................] - ETA: 519s - loss: 4.4794 - pred_prob_loss: 0.8100 - decoder_1_loss: 7338.7740 - pred_prob_acc: 0.1238"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-2ea6bf0b119e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcaps_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-eb552c73f3f2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    102\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                             callbacks=[checkpointer, tb])\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/a.dalmia/tfenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "caps_net.train(model=train_model)"
=======
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> 3e152b6e6829d80cb4b527d9dce79e791f3284e9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
